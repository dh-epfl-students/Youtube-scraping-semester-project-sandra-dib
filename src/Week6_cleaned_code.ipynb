{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c467e6",
   "metadata": {},
   "source": [
    "## Web scraping \n",
    "\n",
    "Goal : get a table of all the locations listed [here](https://en.wikipedia.org/wiki/Lists_of_World_Heritage_Sites), in the format \\[url; name; coordinates\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829a1375",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unicodedata2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/3587870168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlxml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0municodedata2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unicodedata2'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import unicodedata2 as unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aada190",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url=\"https://en.wikipedia.org/wiki/Lists_of_World_Heritage_Sites\")\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "title = soup.find(id=\"firstHeading\")\n",
    "\n",
    "# Get all the links\n",
    "allLinks = soup.find(id=\"bodyContent\").find_all(\"a\")\n",
    "\n",
    "\n",
    "link_list = []\n",
    "str_link = str(allLinks).split('<a')\n",
    "\n",
    "for link in str_link:\n",
    "    if 'href=\"/wiki/' in link:\n",
    "        link_list.append(link)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2809ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "links1 = []\n",
    "for elem in soup.select(\"a[href*=wiki\\/List_of]\"):\n",
    "    links1.append(elem['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d38600",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unicodedata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/414783618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# add information to the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mlocation_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NFKD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s;%s;%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Site'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unicodedata' is not defined"
     ]
    }
   ],
   "source": [
    "# create a csv file\n",
    "with open('../data/unesco_sites_raw.csv', 'w') as f:\n",
    "\n",
    "    for link in links1:\n",
    "        response = requests.get(url = 'https://en.wikipedia.org' + link)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table',{'class':\"wikitable\"})\n",
    "        df = pd.read_html(str(table))\n",
    "\n",
    "        # convert list to dataframe\n",
    "        df = pd.DataFrame(df[0])\n",
    "        newdf = df.fillna('')\n",
    "\n",
    "        # drop the unwanted column\n",
    "        if 'Site' in newdf.columns and 'Location' in newdf.columns:\n",
    "            data = newdf[['Site', 'Location']]\n",
    "\n",
    "            # add information to the csv file\n",
    "            for index, value in data.iterrows():\n",
    "                location_cleaned = unicodedata.normalize('NFKD', value['Location']).encode('ascii','ignore').decode('ascii').replace(';', ',')\n",
    "                f.write(\"%s;%s;%s\\n\" % (link, value['Site'], location_cleaned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc80ef1",
   "metadata": {},
   "source": [
    "### Clean the data \n",
    "Clean the text related to place entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff5989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from tqdm.autonotebook import tqdm\n",
    "from Levenshtein import distance as lev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86044f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/unesco_sites_raw.csv', delimiter=';', header = None)\n",
    "data.rename(columns = {0: 'link', 1: 'place', 2: 'location'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ced6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['place'] = data['place'].apply(lambda x: x.replace(\"-\",\" \"))\n",
    "data['place'] = data['place'].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', x))\n",
    "data['place'] = data['place'].apply(lambda x: x.strip())\n",
    "data['place'] = data['place'].apply(lambda x: x.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c3196b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'place'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/3268025445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dhlab_project/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'place'"
     ]
    }
   ],
   "source": [
    "len(data), len(data.place.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5a8b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aapravasi Ghat</td>\n",
       "      <td>Port Louis District, Mauritius.mw-parser-outpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abu Mena</td>\n",
       "      <td>Abusir, Egypt30°50′28″N 29°39′47″E﻿ / ﻿30.8409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air and Ténéré Natural Reserves</td>\n",
       "      <td>Arlit Department, Niger18°N 9°E﻿ / ﻿18°N 9°E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aksum</td>\n",
       "      <td>Tigray Region, Ethiopia14°07′49″N 38°43′07″E﻿ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al Qal'a of Beni Hammad</td>\n",
       "      <td>Maadid, Algeria35°49′06″N 4°47′13″E﻿ / ﻿35.818...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Site  \\\n",
       "0                   Aapravasi Ghat   \n",
       "1                         Abu Mena   \n",
       "2  Air and Ténéré Natural Reserves   \n",
       "3                            Aksum   \n",
       "4          Al Qal'a of Beni Hammad   \n",
       "\n",
       "                                            Location  \n",
       "0  Port Louis District, Mauritius.mw-parser-outpu...  \n",
       "1  Abusir, Egypt30°50′28″N 29°39′47″E﻿ / ﻿30.8409...  \n",
       "2       Arlit Department, Niger18°N 9°E﻿ / ﻿18°N 9°E  \n",
       "3  Tigray Region, Ethiopia14°07′49″N 38°43′07″E﻿ ...  \n",
       "4  Maadid, Algeria35°49′06″N 4°47′13″E﻿ / ﻿35.818...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9ada19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/2484137340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mplace1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplace2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplace2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if the writing of the place differs of less than 2 characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplace1\u001b[0m \u001b[0;31m# only the first version of the writing is kept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data) - 1)):\n",
    "    place1 = data.iloc[i].place\n",
    "    place2 = data.iloc[i+1].place\n",
    "    if lev(place1, place2) < 3: # if the writing of the place differs of less than 2 characters\n",
    "        data.iloc[i+1].place = place1 # only the first version of the writing is kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93983d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['place'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/3930518811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'place'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhlab_project/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhlab_project/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6061\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6062\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6063\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6065\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dhlab_project/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6195\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Index(['place'], dtype='object')"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = 'place', keep='first',inplace=True)\n",
    "data.sort_values('place', ascending=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb1adfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'place'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_763812/219924487.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check that all names of places are unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dhlab_project/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'place'"
     ]
    }
   ],
   "source": [
    "# check that all names of places are unique\n",
    "len(data), len(data.place.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3261aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe \n",
    "data.to_csv('../data/unesco_sites_cleaned.csv', sep = ';', header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8924d9",
   "metadata": {},
   "source": [
    "## Video search\n",
    "\n",
    "Get all the links resulting from the youtube requests. Refer to video-search.py for the python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b2e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_763812/1353721322.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import youtube_dl\n",
    "import csv\n",
    "import urllib\n",
    "import urllib.request\n",
    "import re\n",
    "import unidecode\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pytube\n",
    "import pandas as pd\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76029684",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = csv.reader(open('../data/unesco_sites_cleaned.csv','r'), delimiter=';')\n",
    "\n",
    "ydl_opts = {\n",
    "'format': 'bestaudio/best',\n",
    "'outtmpl': 'tmp/%(id)s.%(ext)s',\n",
    "'noplaylist': True,\n",
    "'quiet': True,\n",
    "'prefer_ffmpeg': True,\n",
    "'audioformat': 'wav',\n",
    "'forceduration':True\n",
    "}\n",
    "\n",
    "# create an empty dictionnary\n",
    "video_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "017d2e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aapravasi Ghat', 'Port Louis District,\\xa0Mauritius.mw-parser-output .geo-default,.mw-parser-output .geo-dms,.mw-parser-output .geo-dec{display:inline}.mw-parser-output .geo-nondefault,.mw-parser-output .geo-multi-punct{display:none}.mw-parser-output .longitude,.mw-parser-output .latitude{white-space:nowrap}20°09′31″S 57°30′11″E\\ufeff / \\ufeff20.158611°S 57.503056°E']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecb2c4556e640c1bc386f772ab18fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] _CU1pndJgQw: Downloading webpage\n",
      "[youtube] _CU1pndJgQw: Downloading MPD manifest\n",
      "[youtube] gKRtzTDmTiE: Downloading webpage\n",
      "[youtube] gKRtzTDmTiE: Downloading MPD manifest\n",
      "[youtube] EgvQojibIfc: Downloading webpage\n",
      "[youtube] EgvQojibIfc: Downloading MPD manifest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read line by line\n",
    "for row in inputfile:\n",
    "    \n",
    "    print(row)\n",
    "    # get second column (names of places)\n",
    "    place = row[1]\n",
    "    \n",
    "    # clean string : remove accents\n",
    "    place_clean1 = unidecode.unidecode(place)\n",
    "    # clean string : remove spaces\n",
    "    place_clean2 = place_clean1.replace(' ', '+')\n",
    "    \n",
    "    # add key words \n",
    "    search_words = place_clean2 + \"+drone\"\n",
    "    \n",
    "    # make a request in youtube, store the results in a list\n",
    "    results = []\n",
    "    html = urllib.request.urlopen(\"https://www.youtube.com/results?search_query=\" + search_words)\n",
    "    \n",
    "    # store the results\n",
    "    video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.read().decode())\n",
    "  \n",
    "    for video_id in tqdm(video_ids):\n",
    "        try:\n",
    "            ydl_opts = {'ignoreerrors': True}\n",
    "            with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "                myVideo = YouTube(\"https://www.youtube.com/watch?v=%s\" % video_id)\n",
    "                if (myVideo.streams.filter(res=\"2160p\") != None) :\n",
    "                    if not myVideo.age_restricted:\n",
    "                        dictMeta = ydl.extract_info(\"https://www.youtube.com/watch?v=%s\" % video_id, download=False)\n",
    "            \n",
    "                        video_dict.update({video_id : [place_clean1, dictMeta['duration'], dictMeta['title'], dictMeta['upload_date']]})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"ERROR Catched and Passed\", e)\n",
    "            pass \n",
    "        \n",
    "    \n",
    "video_df = pd.DataFrame.from_dict(video_dict, orient='index', columns=['place', 'duration', 'title', 'date'])\n",
    "\n",
    "video_df.to_csv('../data/video_info.csv', index_label = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278d6d0",
   "metadata": {},
   "source": [
    "## Screenshots\n",
    "\n",
    "Select randomly 10 places, from which select 10 random videos, and take 3 screenshots for each video without downloading it for analysis purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import youtube_dl\n",
    "import numpy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/video_info.csv', delimiter=',')\n",
    "dict_sample = {}\n",
    "places_sel = random.sample(df.place.unique().tolist(), 10)\n",
    "for place in places_sel:\n",
    "    ids = df.loc[df['place'] == place].id.tolist()\n",
    "    ids_sample = random.sample(ids, 10)\n",
    "    dict_sample.update({place : ids_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict_sample.items():\n",
    "    \n",
    "    place = key\n",
    "    for youtube_id in value:\n",
    "        print(youtube_id)\n",
    "        video_url = 'https://www.youtube.com/watch?v=%s' % youtube_id  #The Youtube URL\n",
    "        ydl_opts = {}\n",
    "        ydl = youtube_dl.YoutubeDL(ydl_opts)\n",
    "        info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "        formats = info_dict.get('formats',None)\n",
    "\n",
    "        f = formats[-1]\n",
    "        url = f.get('url',None)\n",
    "        cap = cv2.VideoCapture(url)\n",
    "\n",
    "        x = 1\n",
    "        count = info_dict['duration'] / 4\n",
    "\n",
    "        while x < 4 :\n",
    "\n",
    "            for i in range(3):\n",
    "\n",
    "                time = x * info_dict['duration'] + ( 10 * i ) # each time, take 3 shots at 10 sec intervals\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                filename = \"../data/screenshots/%s-%d.png\" % (youtube_id, time)\n",
    "\n",
    "                cv2.imwrite(filename, frame)\n",
    "                count += int(info_dict['duration'] / 4)\n",
    "                cap.set(1,count)\n",
    "\n",
    "            x += 1\n",
    "\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64d4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
